{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob, Word, Blobber\n",
    "import newspaper\n",
    "from newspaper import Article\n",
    "import operator\n",
    "import rake as rake\n",
    "from datetime import datetime\n",
    "rake_object = rake.Rake(\"SmartStoplist.txt\", 1, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the function in run_praw.py, so I'm using it as a reference for all my algs\n",
    "def display_praw(name, num):\n",
    "    reddit = praw.Reddit(client_id='Pj5o8QpNXXJY9A',\n",
    "                         client_secret='pQKMRBmhp0In48NoNvvktfRo2eA',\n",
    "                         password='prawisgreat',\n",
    "                         user_agent='Reddit Unlocked CS196 Project @ UIUC',\n",
    "                         username='RedditUnlocked196')\n",
    "\n",
    "    subreddit = reddit.subreddit(name)\n",
    "\n",
    "    threads_df = pd.DataFrame({\n",
    "        'Title': (),\n",
    "        'URL': (),\n",
    "        'Upvote Ratio (%)': (),\n",
    "        'Net Score': (),\n",
    "        '# of Upvotes': (),\n",
    "        '# of Downvotes': (),\n",
    "        'Post Date': (),\n",
    "        'Self Post?': (),\n",
    "        'Video Post?': (),\n",
    "        'Domain': ()\n",
    "    })\n",
    "\n",
    "    threads_df = threads_df[['Title', 'URL', 'Upvote Ratio (%)', 'Net Score', '# of Upvotes', '# of Downvotes',\n",
    "                             'Post Date', 'Self Post?', 'Video Post?', 'Domain']]\n",
    "\n",
    "    for thread in subreddit.top('year', limit=num): # TODO: change limit number when actually deploying program. 15 is the testing number.\n",
    "        actualUps = int((thread.upvote_ratio * thread.score) / (thread.upvote_ratio * 2 - 1))\n",
    "        actualDowns = actualUps - thread.score\n",
    "        gather = pd.Series([thread.title, thread.url, thread.upvote_ratio * 100, thread.score,\n",
    "                            actualUps, actualDowns, thread.created_utc,\n",
    "                            thread.is_self, thread.is_video, thread.domain],\n",
    "                           index=['Title', 'URL', 'Upvote Ratio (%)', 'Net Score', '# of Upvotes', '# of Downvotes',\n",
    "                                  'Post Date', 'Self Post?', 'Video Post?', 'Domain'])\n",
    "        threads_df = threads_df.append(gather, ignore_index=True)\n",
    "\n",
    "    threads_dict = threads_df.to_dict(orient='records')\n",
    "\n",
    "    for entry in threads_dict:\n",
    "        if isinstance(str(entry['Post Date']), str):\n",
    "            time = datetime.fromtimestamp(entry['Post Date'])\n",
    "            formatTime = time.strftime('%b %d, %Y')\n",
    "        else:\n",
    "            formatTime = None\n",
    "\n",
    "        entry['Post Date'] = formatTime\n",
    "\n",
    "    return threads_dict\n",
    "\n",
    "\n",
    "def get_keyword_dict(num):\n",
    "    # Transforms dict returned by display_praw into DataFrame for working with\n",
    "    top10news_df = pd.DataFrame.from_dict(display_praw('news', num))\n",
    "\n",
    "    words = {}\n",
    "\n",
    "    ## NEWSPAPER STUFF HERE ##\n",
    "\n",
    "    # Get keywords out of all articles\n",
    "    for i in range(len(top10news_df)):\n",
    "        #top10news_df.iloc[i]['url']\n",
    "        myArticle = Article(top10news_df.iloc[i]['URL'])\n",
    "        myArticle.download()\n",
    "        myArticle.parse()\n",
    "        myArticle.nlp()\n",
    "\n",
    "        # Run sentiment analysis on each article, fetch subjectivity and polarity\n",
    "        text = myArticle.text\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "        # Get associated Reddit post info for each keyword, store in dictionary\n",
    "        for keyword in myArticle.keywords:\n",
    "\n",
    "            # Don't waste time with numeric keywords, skip them if they contain numbers\n",
    "            if any(char.isdigit() for char in keyword):\n",
    "                continue        \n",
    "\n",
    "            if keyword not in words:\n",
    "                words[keyword] = [keyword, 1, \n",
    "                                  top10news_df.iloc[i]['# of Upvotes'],\n",
    "                                  top10news_df.iloc[i][\"# of Downvotes\"], \n",
    "                                  top10news_df.iloc[i][\"Net Score\"],\n",
    "                                  subjectivity, polarity, \n",
    "                                  {(top10news_df.iloc[i][\"Domain\"]):1}]\n",
    "            else:\n",
    "                words[keyword][1] += 1\n",
    "                words[keyword][2] += top10news_df.iloc[i]['# of Upvotes']\n",
    "                words[currentWord][3] += int(top10news_df.iloc[i]['# of Downvotes'])\n",
    "                words[currentWord][4] += int(top10news_df.iloc[i]['Net Score'])\n",
    "                words[currentWord][5] = np.mean([subjectivity, words[currentWord][5]])\n",
    "                words[currentWord][6] = np.mean([polarity, words[currentWord][6]])\n",
    "                if top10news_df.iloc[i][\"Domain\"] in words[currentWord][7]:\n",
    "                    words[currentWord][7][(top10news_df.iloc[i][\"Domain\"])] += 1\n",
    "                else:\n",
    "                    words[currentWord][7][top10news_df.iloc[i][\"Domain\"]] = 1\n",
    "\n",
    "        ## RAKE STUFF HERE ##\n",
    "\n",
    "        # Pull keywords from title strings\n",
    "        for wordPair in rake_object.run(top10news_df.iloc[i]['Title']):\n",
    "            currentWord = wordPair[0]\n",
    "\n",
    "            # Don't waste time with numeric keywords, skip them if they contain numbers\n",
    "            if any(char.isdigit() for char in currentWord):\n",
    "                continue\n",
    "\n",
    "            # Grab associated Reddit post data for each keyword, store in dictionary\n",
    "            if currentWord not in words:\n",
    "                words[currentWord] = [currentWord, 1, \n",
    "                                  top10news_df.iloc[i]['# of Upvotes'],\n",
    "                                  top10news_df.iloc[i][\"# of Downvotes\"], \n",
    "                                  top10news_df.iloc[i][\"Net Score\"],\n",
    "                                  subjectivity, polarity, \n",
    "                                  {(top10news_df.iloc[i][\"Domain\"]):1}]\n",
    "            else:\n",
    "                words[currentWord][1] += 1\n",
    "                words[currentWord][2] += int(top10news_df.iloc[i]['# of Upvotes'])\n",
    "                words[currentWord][3] += int(top10news_df.iloc[i]['# of Downvotes'])\n",
    "                words[currentWord][4] += int(top10news_df.iloc[i]['Net Score'])\n",
    "                if top10news_df.iloc[i][\"Domain\"] in words[currentWord][7]:\n",
    "                    words[currentWord][7][(top10news_df.iloc[i][\"Domain\"])] += 1\n",
    "                else:\n",
    "                    words[currentWord][7][top10news_df.iloc[i][\"Domain\"]] = 1\n",
    "\n",
    "\n",
    "    ### FOR GARY'S USE ###\n",
    "    # Output dictionary is named 'words' #\n",
    "    # Format is as such: #\n",
    "    # key = keyword #\n",
    "    # value = [Occurences, Upvotes, Downvotes, Score, Subjectivity, Polarity, Domain Dictionary] #\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-a849fe1dbb8b>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a849fe1dbb8b>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "# Runtime comparison\n",
    "original_start = datetime.now()\n",
    "\n",
    "timings = []\n",
    "for i in range(5, 105, 5):\n",
    "    start_time = datetime.now()\n",
    "    get_keyword_dict(i)\n",
    "    time_taken = datetime.now() - start_time\n",
    "    timings.append((i, time_taken))\n",
    "\n",
    "final = datetime.now() - original_start\n",
    "print(\"Total time taken: %d\" % final)\n",
    "\n",
    "for pair in timings:\n",
    "    plt.scatter(pair[0], pair[1])\n",
    "    plt.plot(pair[0], pair[1])\n",
    "plt.xlabel(\"Number of Posts Parsed\")\n",
    "plt.ylabel(\"Processing Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
